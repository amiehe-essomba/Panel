{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <!-- TITLE --> __```Exploration des données + Data Viz```__\n",
    "<img width=\"1000px\" height=\"400px\" src=\"images/out.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  __```Importations des modules Python```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd  \n",
    "import numpy  as np \n",
    "import seaborn as sns \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Importations des modules Python externes```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules_python.file_extraction.extraction import read_plant_datasets\n",
    "from modules_python.config.cmap import color_map as cmap\n",
    "from modules_python.config.plot_images import plot as plot_img\n",
    "from modules_python.image_processing.SemanticImage import SemanticImage\n",
    "from modules_python.plots.plot import hist_hist_plot, hist_bar_plot, hist_pie_plot, boxplot\n",
    "from modules_python.image_processing.preprocessing import  filter_selection\n",
    "from modules_python.image_processing.data_aug import data_augmenter_v1 as data_aug\n",
    "from modules_python.image_processing.ImageSeg import ImageSegmentation\n",
    "from modules_python.image_processing.tools import change_bg\n",
    "from modules_python.image_processing.preprocessing import Semantic_Image_Plus_Data_Augment\n",
    "from modules_python.models.cnn.layers import convNet_m1\n",
    "from modules_python.models.cnn.layers import compilation \n",
    "from modules_python.image_processing.data_aug import data_augmenter_v2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Liste des Couleurs disponibles```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste de couleurs\n",
    "python_colors = list(mcolors.CSS4_COLORS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Liste des Couleurs de mappage```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappage des couleurs\n",
    "python_colors_map = cmap().get_cmap_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Définir le chemin d'accès du dataset```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre son chemin ici, différent pour tout le monde (Iréné)\n",
    "PATH = \"C:\\\\Users\\\\amib\\Documents\\\\Py_Projects\\\\DS_project\\\\especes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Extraction & Lecture des données```__\n",
    "\n",
    "- Plus de détails sur les différents paramètres [ici](https://github.com/amiehe-essomba/Plant_Seedlings_ds_Project/blob/Plant_Seedlings/details.md)\n",
    "- Source des données : [Kaggle V2 Plant Seedlings Dataset](https://www.kaggle.com/datasets/vbookshelf/v2-plant-seedlings-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombres d'espèces de plantes\n",
    "samples         = 12\n",
    "\n",
    "# pas\n",
    "pas             = 1\n",
    "\n",
    "# extraction de tout le dataset (samples = 12 et pas = 1)\n",
    "type_indexes    = [x for x in range(0, samples, pas) ]\n",
    "\n",
    "# type de filtre utilisé\n",
    "channel_type    = \"RGR2-LAB\"\n",
    "\n",
    "# fenêtres de redimensionnement \n",
    "reshape         = [(128, 128)]\n",
    "\n",
    "# format de données\n",
    "return_as       = \"dict\"\n",
    "\n",
    "# verbose\n",
    "verbose         = 1\n",
    "\n",
    "# ajout de l'intensité lumineuse sur les 3 canaux\n",
    "add_contrast    = False \n",
    "\n",
    "# début de l'extraction des fichiers\n",
    "DATA            = read_plant_datasets(\n",
    "                        path        = PATH, \n",
    "                        reshape     = reshape, \n",
    "                        return_as   = return_as, \n",
    "                        verbose     = verbose, \n",
    "                        type_indexes= type_indexes, \n",
    "                        channel_type= channel_type,\n",
    "                        add_contrast= add_contrast\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Chargement des données```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection de la taille des image\n",
    "shape           = reshape[0]\n",
    "\n",
    "# extraction & chargement (EL)\n",
    "data            = DATA[f\"{shape[0]}x{shape[1]}\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir la légende (noms des plantes)\n",
    "legend          = data['feature_names']\n",
    "\n",
    "# définir les coleurs pour chaque plantes du dataset\n",
    "colors          = [\"blue\", 'orange', 'darkgreen', 'darkred', 'm', \"c\", \"lime\", \"k\", \"y\", \"violet\", \"gold\", \"darkblue\" ]\n",
    "# le choix des couleurs peut également de faire comme suite \n",
    "#colors = random.sample(python_colors, samples) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Visualisation des différentes espèces de plantes en RBG et sous Infra-Rouge```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Section de visualisation sur le canal 1.\n",
    "à Savoir que, pour une bonne représentation des coleurs toutes les images ont 3 canaux (RGB2-LAB)\n",
    "\"\"\"\n",
    "\n",
    "# choisir l'unique valeur pour toutes les plantes (image uinique)\n",
    "index           = 10\n",
    "\n",
    "for s in ['images', 'X']:\n",
    "    # choisir le canal de couleur (axis=1)\n",
    "    channel         = 1\n",
    "\n",
    "    # types d'images {X : RGR2-LAB, images : images réelles}\n",
    "    type_img        = s\n",
    "\n",
    "    # indice de la couleur de mappage (2D)\n",
    "    id_cmap         = 10\n",
    "    \n",
    "    colors = ['k' for x in range(12)]\n",
    "    # visualisation des images dans l'infra-rouge\n",
    "    plot_img(\n",
    "        data        = data,                         # both\n",
    "        index       = index,                        # both\n",
    "        channel     = channel,                      # both \n",
    "        colors      = colors,                       # both (title's colors)\n",
    "        legend      = legend,                       # both \n",
    "        type_img    = type_img,                     # both \n",
    "        cmap        = python_colors_map[id_cmap],   # fig bottom (RGR2-LAB)\n",
    "        save        = True,                         # fig bottom (RGR2-LAB)\n",
    "        fig_name    =  \"rgb.png\"                    # fig top (RGB)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Analyses des Images```__\n",
    "- *[Intialisation des paramètres]()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices associés à chaque espèces de plantes\n",
    "id_sel      = [1, 3, 5, 7, 9, 11] # [0, 2, 4, 6, 8, 10]#\n",
    "# Sous legendes\n",
    "sub_lengend = [legend[q] for q in id_sel]\n",
    "# Sous coleurs \n",
    "# random.sample(python_colors, k=len(id_sel))\n",
    "sub_colors  = [\"darkblue\", 'darkorange', 'green', 'red', 'm', 'skyblue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- *[Hauteur & Largeur (n_H x n_L)]()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hauteurs (n_H)\n",
    "Hauteus     = [data['height'][i] for i in id_sel]\n",
    "# Largeurs (n_L)\n",
    "Largeurs    = [data['width'][i] for i in id_sel] \n",
    "# Concatenation\n",
    "X           = [Hauteus, Largeurs]\n",
    "# titles \n",
    "titles      = [\"Histogramme des hauteurs\", \"Histogrammes de Largeurs\"]\n",
    "# xlabels \n",
    "xlabel      = ['Hauteur', \"Largeur\"]\n",
    "# ylabels \n",
    "ylabel      = [\"Population\", \"Population\"]\n",
    "# figsize   \n",
    "figsize     = (12, 3)\n",
    "# bonding box coordinates \n",
    "coord   : dict = {\"x\" : [[10, 250], [10, 250]], \n",
    "                        \"y\" : [[0, 450], [0, 450]], \"xmin\":[0, 0], \"ymin\":[0, 0],\n",
    "                        \"xmax\" : [250, 250], \"ymax\" :  [450, 450]}\n",
    "\n",
    "hist_hist_plot(\n",
    "    X           = X,                # both \n",
    "    legend      = sub_lengend,      # both \n",
    "    title       = titles,           # both \n",
    "    xlabel      = xlabel,           # both \n",
    "    ylabel      = ylabel,           # both \n",
    "    colors      = sub_colors,       # both\n",
    "    figsize     = figsize,          # both \n",
    "    bonding_box = True,             # both \n",
    "    annot       = True,             # both \n",
    "    text        = True,             # both\n",
    "    coord       = coord,            # both\n",
    "    y_lim       = [-5, 500],        # both \n",
    "    bins        = 8,                # both\n",
    "    save        = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *[Pixellisations & Répartition d'espèces]()*\n",
    "\n",
    "| __Noms d'espèces__                    | __Nombre de plantes par espèce__ | __RGBA (RGB + canal alpha)__  |__[Total]()__|\n",
    "|---------------------------------------|----------------------------------|-----------------------------|------|\n",
    "| __Black-grass__                       | __309__               | __3__|\n",
    "| __Charlock__                          | __452__               | __0__|\n",
    "| __Cleavers__                          | __335__               | __0__|\n",
    "| __Common Chickweed__                  | __713__               | __0__|\n",
    "| __Common wheat__                      | __253__               | __0__|\n",
    "| __Fat Hen__                           | __538__               | __0__|\n",
    "| __Loose Silky-bent__                  | __762__               | __21__|\n",
    "| __Maize__                             | __257__               | __0__|\n",
    "| __Scentless Mayweed__                 | __607__               | __0__|\n",
    "| __Shepherdoco Purse__                 | __274__               | __0__|\n",
    "| __Small-flowered Cranesbill__         | __576__               | __0__|\n",
    "| __Sugar beet__                        | __463__               | __0__|\n",
    "|  __[Total]()__                        | __[5539]()__                     | __[24]()__      |__[12 espèces]()__|\n",
    "\n",
    "- Valeurs Statistiques\n",
    "\n",
    "|__Min__        | __Max__     | __Mean__         | __Med__        | __std__       | __Q1__         | __Q3__       | __IQ__        |\n",
    "|---------------|-------------|------------------|----------------|---------------|----------------|--------------|---------------|\n",
    "|  __[253]()__  | __[762]()__ | __[462.6]()__    | __[457.5]()__  | __[179.3]()__ | __[300.3]()__  |__[583.8]()__ | __[283.5]()__ |\n",
    "\n",
    "\n",
    "\n",
    "* Voir [Boxplot](#boxplot)  bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- [Boxplot](#boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num   = pd.Series(data = data['number_of_images'], name='spaces') \n",
    "boxplot(X=num, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une Series pour stocker le nombre d'images par espèves\n",
    "num_of_images   = pd.Series(data = [data['number_of_images'][q] for q in id_sel ], name='spaces').values\n",
    "# gama\n",
    "gama            = pd.Series(data = data['number_of_images'], name='spaces').values\n",
    "# pixels\n",
    "Pixels          = [data['pixels'][q] for q in id_sel]\n",
    "# titles \n",
    "titles          = [\"Histogramme de pixelisation\", \"Nombre de plantes par espèce\"]\n",
    "# xlabels \n",
    "xlabel          = [\"Pixels (Mpx)\", \"Encodage\"]\n",
    "# ylabels \n",
    "ylabel          = [\"Population\", \"Population\"]\n",
    "# Concatenation\n",
    "X               = [Pixels, num_of_images]\n",
    "\n",
    "hist_bar_plot(\n",
    "    X           = X,                        # both\n",
    "    figsize     = figsize,                  # both\n",
    "    colors      = sub_colors,               # both\n",
    "    legend      = sub_lengend,              # both\n",
    "    xlabel      = xlabel,                   # fig 1 \n",
    "    ylabel      = ylabel,                   # fig 1\n",
    "    titles      = titles,                   # fig 1\n",
    "    rot         = 45,                       # fig 2\n",
    "    bb_box      = {\"x\" : 0.5, \"y\" : 600},   # fig 1\n",
    "    legends     = legend,                   # fig 2\n",
    "    y_lim       = [[-5, 750], [-5, 770]] ,  # both\n",
    "    encoding    = True,                     # fig 2\n",
    "    sort        = True,                     # fig 2\n",
    "    rev         = True,                     # fig 2\n",
    "    bar_bbox    = (1.1, 0.6, 0.5, 0.5),     # fig 2\n",
    "    gama        = gama,                     # fig 2\n",
    "    c           = 'k',                      # fig 2\n",
    "    bins        = 8,                        # fig 1\n",
    "    width       = 0.5,                      # fig 2\n",
    "    save        = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *[Longueur/Hauteur & Canaux RGBA(GRB + canal alpha)]()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y(widths, heights, size : int = 3):\n",
    "    # cacul du rapport width / height \n",
    "    return [np.array(widths[i]) / np.array(heights[i]) for i in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_box              = {\"x\":1.02, \"y\":600}\n",
    "# création d'une Series pour stocker le nombre d'images par espèves\n",
    "X_Y                 = x_y(heights=Hauteus, widths=Largeurs, size=len(sub_lengend))\n",
    "# pixels\n",
    "Sobels              = [data['sobels'][q] for q in [0, 1, 3, 6, 9, 11]]\n",
    "# Sobel_legends \n",
    "Sobel_legends       = [legend[q] for q in [0, 1, 3, 6, 9, 11]]\n",
    "# Concatenation\n",
    "X                   = [X_Y, Sobels]\n",
    "\n",
    "if      sum(Sobels) == 0: figsize_=(6, 3)\n",
    "else:   figsize_    = (12, 3)\n",
    "\n",
    "hist_pie_plot(\n",
    "    X               = X,                    # both\n",
    "    legend          = sub_lengend,          # fig 1\n",
    "    colors          = sub_colors,           # both\n",
    "    bb_box          = bb_box,               # fig 1\n",
    "    figsize         = figsize_,             # fig 1\n",
    "    vline           = True,                 # fig 1 (show vertical line)\n",
    "    xlabel          = ['Ratio (L/H)', \"\"],  # fig 1\n",
    "    ylabel          = ['Population', \"\"],   # fig 1\n",
    "    y_lim           = [-5, 800],            # fig 1\n",
    "    x_lim           = [0.99, 1.1],          # fig 1\n",
    "    Sobel_legends   = Sobel_legends,        # fig 2\n",
    "    radius          = 1.2,                  # fig 2 (circle radius)\n",
    "    explode_id      = [1],                  # fig 2 \n",
    "    titles          = ['Hitogramme (L/H)'], # fig 1\n",
    "    v_line          = False,                # fig 1\n",
    "    save            = False,\n",
    "    pctdistance     = 0.80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *[Histogrammes de couleurs en RGR2-LAB( 3 canaux )]()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection d'images RGR2-LAB\n",
    "images  =  [data['X'][m][index].astype(\"float32\").copy() for m in range(12)]#id_sel\n",
    "\n",
    "# Visualisations graphiques des histogrammes de couleurs sur les 3 axes [0, 1, 2]  \n",
    "filter_selection(\n",
    "    img             = images, \n",
    "    names           = legend,  #sub_lengend\n",
    "    select_index    = [x for x in range(12)], \n",
    "    figsize         = (15,24), \n",
    "    bins            = 20\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __```Segmentation d'Images Sémantqiues(SIS) Différentes étapes```__\n",
    "Comment effectuer la [Segmentation d'Images Sémantiques]()\n",
    "* [REF. 1](https://fr.wikipedia.org/wiki/Segmentation_d%27image)\n",
    "* [REF. 2](https://nanonets.com/blog/semantic-image-segmentation-2020/)\n",
    "* [REF. 3](https://towardsdatascience.com/semantic-segmentation-popular-architectures-dff0a75f39d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seuils de valeurs RGB de l'arrère plan(background) voir ( l'histogramme de couleurs du canal 1 )\n",
    "threshold   = [0, 0.465]\n",
    "\n",
    "# seuils max du noir sur une échelle de [0, 255] pour les 3 canaux\n",
    "upper_color = [30, 30, 30]\n",
    "\n",
    "# seuils min du noir sur une échelle de [0, 255] pour les 3 canaux\n",
    "lower_color = [0, 0, 0]\n",
    "\n",
    "# rayon utilisé pour la dilatation et l'érosion\n",
    "radius      = 1\n",
    "\n",
    "# méthode de segmentation  utilisée\n",
    "method      = \"numpy\"\n",
    "# visualisation des images dans l'infra-rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = python_colors_map[id_cmap]\n",
    "bg='all'\n",
    "SemanticImage(\n",
    "        data        = data,\n",
    "        index       = index,\n",
    "        channel     = channel,\n",
    "        threshold   = threshold,\n",
    "        upper_color = upper_color,\n",
    "        lower_color = lower_color,\n",
    "        legend      = legend,\n",
    "        radius      = radius,\n",
    "        method      = method,\n",
    "        bg          = bg,\n",
    "        id_sel      = id_sel, \n",
    "        deep_mask   = True,\n",
    "        kernel      = (2, 2),\n",
    "        cmap        = cmap,\n",
    "        figsize     = (15, 12),\n",
    "        value       = [1, 1, 1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index   = 1\n",
    "_image_seg_     = ImageSegmentation(\n",
    "        img=data['X'][feature_index][index].astype(np.float32).copy(),\n",
    "        src=data['images'][feature_index][index].astype(np.float32).copy(),\n",
    "        threshold=threshold, \n",
    "        radius=radius,\n",
    "        shape=shape,\n",
    "        axis=channel,\n",
    "        method=method\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_aug = data_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(18):\n",
    "    for j in range(1):\n",
    "        plt.subplot(3, 6, i+j+1)\n",
    "        if i != 0 : \n",
    "            XX_ = Data_aug(_image_seg_)\n",
    "            XX_ = XX_.numpy().reshape((1, reshape[0][0], reshape[0][1], 3))\n",
    "        else : \n",
    "            XX_ = tf.expand_dims(_image_seg_, 0) \n",
    "            plt.title(\"img originale\", color=\"red\")\n",
    " \n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(XX_[0]) \n",
    "\n",
    "#plt.savefig(\"./images/img_aug.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep             = 12\n",
    "srcs            = data['images'][:sep]\n",
    "imgs            = data['X'][:sep]\n",
    "target          = data['target'][:sep]              # cible\n",
    "threshold       = threshold                         # fenetre du vert dans le RGB2-LAB\n",
    "shape           = (2, 2)                            # nayau de la dilatation + erosion \n",
    "radius          = 2                                 # noyau \n",
    "dil_and_er      = False                             # vrai si application du deep mask\n",
    "color           = \"img\"                           # formats wihite and black \n",
    "formats         = \"128x128\"                         # données traité (160, 160, 3)\n",
    "feature_names   = data['feature_names'][:sep]       # noms des classes\n",
    "paths           = data['paths'][:sep]               # chemins des images\n",
    "resize_dim      = reshape[0] + (3,)                 # reduire la dimension\n",
    "resize          = False                             # accepter le redimensionnement \n",
    "max_per_class   = 3000                              # nombre d'images par classes\n",
    "use_same_samples=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_transform = \\\n",
    "    Semantic_Image_Plus_Data_Augment(\n",
    "    imgs=imgs,\n",
    "    srcs=srcs,\n",
    "    target=target,\n",
    "    feature_names=feature_names,\n",
    "    threshold=threshold,\n",
    "    shape=shape,\n",
    "    radius=radius,\n",
    "    color=color, \n",
    "    upper_color=upper_color,\n",
    "    lower_color=lower_color,\n",
    "    paths=paths, \n",
    "    max_per_class=max_per_class,\n",
    "    resize=resize,\n",
    "    resize_dim=resize_dim,\n",
    "    use_same_samples=use_same_samples,\n",
    "    contrast= False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  \n",
    "x_w = new_data_transform['X:img']\n",
    "x_b = new_data_transform['X:black']\n",
    "idd = random.sample(range(36000), k=1)\n",
    "#x = [x_b[idd], x_w[idd]]\n",
    "x = x_w[idd]\n",
    "t = new_data_transform['target'][idd]\n",
    "t_name = new_data_transform['feature_names'][idd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[0].shape, x[0].min(), x[0].max(), x[1].min(), x[1].max(), x_b.shape\n",
    "x.shape, x.min(), x.max(), x_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(4, 2))\n",
    "for i in range(axes.shape[0]):\n",
    "    axes[i].imshow( x[0] )\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f'{t_name[0]} = {t[0]}', fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = compilation.split_data(\n",
    "    X=new_data_transform['X:img'],\n",
    "    y=new_data_transform[\"target\"],\n",
    "    test_size=0.10,\n",
    "    normalize=False\n",
    ")\n",
    "X_train, X_test, X_dev = data_split['X_train'], data_split['X_test'], data_split[\"X_dev\"]\n",
    "y_train, y_test, y_dev = data_split['y_train'], data_split['y_test'], data_split['y_dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.max(), X_train.max(), X_test.min(), X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_shape : tuple = (128, 128), classes : int = 12):\n",
    "    \n",
    "    # creating the input layer\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # première couche de convolution stride = (4,4), padding=\"valid\", kernel=(11, 11), pol_size = (2,2), filters=96\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=(9, 9), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(2, 2), padding=\"valid\"\n",
    "        )(inputs)\n",
    "    # fonction  d'activation \n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # réduction de dimension par 2\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(2, 2)\n",
    "        )(X)\n",
    "    X = tf.keras.layers.Dropout(rate=0.4)(X)\n",
    "\n",
    "    # deuxième couche de convolution stride = (1,1), padding=\"valid\", kernel=(5,5), pol_size = (2,2), filters=256\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=(7, 7), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(1, 1), padding=\"valid\"\n",
    "        )(X)\n",
    "    # fonction  d'activation \n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # réduction de dimension par 2\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(1, 1), padding=\"valid\"\n",
    "        )(X)\n",
    "    X = tf.keras.layers.Dropout(rate=0.4)(X)\n",
    "\n",
    "    # troisième couche de convolution stride = (1,1), padding=\"valid\", kernel=(5,5), pol_size = (1, 1), filters =384\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=128, kernel_size=(3, 3), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(1, 1), padding=\"valid\"\n",
    "        )(X)\n",
    "    # fonction d'activation\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # conversation de la taille de l'image padding = \"same\" ---> stride = (1, 1)\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(1, 1), padding=\"valid\"\n",
    "        )(X)\n",
    "    X = tf.keras.layers.Dropout(rate=0.3)(X)\n",
    "\n",
    "    # quatrième couche de convolution stride = (1,1), padding=\"valid\", kernel=(1, 1), \n",
    "    # filters =384, pol_size = (1, 1), drop_out = 0.7\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=126, kernel_size=(3, 3), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(1, 1), padding=\"valid\"\n",
    "        )(X)\n",
    "    # fonction d'activation\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # conversation de la taille de l'image padding = \"same\" ---> stride = (1, 1)\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(1, 1) \n",
    "        )(X)\n",
    "    # déconnection de 20 % des couches de façon random pour limiter le surapprentissage \n",
    "    X = tf.keras.layers.Dropout(rate=0.2)(X)\n",
    "\n",
    "    # 5eme couche de convolution stride = (1,1), padding=\"valid\", kernel=(1, 1), filters = 512, drop_out = 0.5\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=384, kernel_size=(3, 3), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(2, 2), padding=\"valid\"\n",
    "        )(X)\n",
    "    # fonction d'activation\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # conversation de la taille de l'image padding = \"same\" ---> stride = (1, 1)\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(1, 1) \n",
    "        )(X)\n",
    "    X = tf.keras.layers.Dropout(rate=0.4)(X)\n",
    "    # 6eme couche de convolution stride = (1,1), padding=\"valid\", kernel=(1, 1), filters = 512, drop_out = 0.5\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=512, kernel_size=(3, 3), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(1, 1), padding=\"valid\"\n",
    "        )(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # conversation de la taille de l'image padding = \"same\" ---> stride = (1, 1)\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(1, 1) \n",
    "        )(X)\n",
    "    X = tf.keras.layers.Dropout(rate=0.5)(X)\n",
    "    # 7eme couche de convolution \n",
    "    \"\"\"\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=1024, kernel_size=(3, 3), \n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        strides=(1, 1), padding=\"same\"\n",
    "        )(X)\n",
    "    # fonction d'activation\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis=3)(X)\n",
    "    # conversation de la taille de l'image padding = \"same\" ---> stride = (1, 1)\n",
    "    X = tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), strides=(1, 1) \n",
    "        )(X)\n",
    "    # déconnection de 20 % des couches de façon random pour limiter le surapprentissage \n",
    "    X = tf.keras.layers.Dropout(rate=0.5)(X)\n",
    "    \"\"\"\n",
    "    # applatissement \n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    # 1ere couche full connected, avec 4096 neurones et relu comme function d'activation\n",
    "    X = tf.keras.layers.Dense(units= 4096, \n",
    "                              activation=tf.keras.activations.relu)(X)\n",
    "    # déconnection de 50 % de neurone de façon random pour limiter le surapprentissage \n",
    "    X = tf.keras.layers.Dropout(rate=0.5)(X)\n",
    "\n",
    "    # couche de classification (12 classes)\n",
    "    X = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.softmax)(X)\n",
    "\n",
    "    # output \n",
    "    outputs = X\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, AveragePooling2D, MaxPool2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import Input, Conv2D, Add, BatchNormalization, ReLU, ZeroPadding2D, MaxPooling2D\n",
    "\n",
    "random_uniform = tf.keras.initializers.random_uniform\n",
    "constant = tf.keras.initializers.constant\n",
    "glorot_uniform = tf.initializers.glorot_uniform\n",
    "\n",
    "def identity_block(X : np.ndarray, filters : list = [], init=glorot_uniform, channels : int = 2):\n",
    "    shape = X.shape[1:]\n",
    "\n",
    "    XX = X\n",
    "  \n",
    "    #Input(shape = shape)\n",
    "    X = Conv2D(filters=filters[0], kernel_size=(1, 1), strides=(1,1), \n",
    "                     padding='valid', kernel_initializer=random_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = ReLU()(X)\n",
    "\n",
    "   \n",
    "    X = Conv2D(filters=filters[1], kernel_size=(channels, channels), strides=(1,1), \n",
    "                                        padding='same', kernel_initializer=random_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = ReLU()(X)\n",
    "\n",
    "    \n",
    "    X = Conv2D(filters=filters[2], kernel_size=(1,1), strides=(1,1), \n",
    "                     padding='valid', kernel_initializer=random_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    \n",
    "    X = Add()([XX, X])\n",
    "    X = ReLU()(X)\n",
    "  \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X : np.ndarray, filters : list = [], init=random_uniform, channels : int =2, s : int = 1):\n",
    "   \n",
    "    XX = X#.copy()\n",
    "  \n",
    "    #Input(shape = shape)\n",
    "    X = Conv2D(filters=filters[0], kernel_size=(1, 1), strides=(s,s), \n",
    "                     padding='valid', kernel_initializer=random_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = ReLU()(X)\n",
    "\n",
    "   \n",
    "    X = Conv2D(filters=filters[1], kernel_size=(channels, channels), strides=(1,1), \n",
    "                                        padding='same', kernel_initializer=random_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = ReLU()(X)\n",
    "\n",
    "    \n",
    "    X = Conv2D(filters=filters[2], kernel_size=(1,1), strides=(1,1), \n",
    "                     padding='valid', kernel_initializer=random_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    # shortcut block \n",
    "    XX = Conv2D(filters=filters[2], kernel_size=(1,1), strides=(s,s), \n",
    "                     padding='valid', kernel_initializer=random_uniform(seed=0))(XX)\n",
    "    XX = BatchNormalization(axis=3)(XX)\n",
    "    \n",
    "    X = Add()([XX, X])\n",
    "    X = ReLU()(X)\n",
    "  \n",
    "    return X\n",
    "\n",
    "def ResNet16(input_shape : tuple = (128, 128, 3), classes : int = 6, training : bool = False, pad : tuple = (3, 3)):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    W, H, C = input_shape\n",
    "    C = 256\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D(padding=pad)(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(filters=64, kernel_size=(3, 3), strides = (1, 1), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = ReLU()(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X=X, channels = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X=X, channels=3, filters=[64, 64, 256])\n",
    "    #X = identity_block(X=X, channels=3, filters=[64, 64, 256])\n",
    "    \n",
    "    # `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X=X, channels = 3, filters = [128,128,512], s = 2)\n",
    "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X=X, channels=3, filters=[128,128,512])\n",
    "    #X = identity_block(X=X, channels=3, filters=[128,128,512])\n",
    "    #X = identity_block(X=X, channels=3, filters=[128,128,512])\n",
    "\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    #X = convolutional_block(X=X, channels= 3, filters = [256, 256, 1024], s = 2)\n",
    "    # the 5 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    #X = identity_block(X=X, channels=3, filters=[256, 256, 1024])\n",
    "    #X = identity_block(X=X, channels=3, filters=[256, 256, 1024])\n",
    "    #X = identity_block(X=X, channels=3, filters=[256, 256, 1024])\n",
    "    #X = identity_block(X=X, channels=3, filters=[256, 256, 1024])\n",
    "    #X = identity_block(X=X, channels=3, filters=[256, 256, 1024])\n",
    "\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X=X, channels = 3, filters = [512, 512, 2048], s = 2)\n",
    "    # the 2 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X=X, channels=3, filters=[512, 512, 2048])\n",
    "    #X = identity_block(X=X, channels=3, filters=[512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL \"X = AveragePooling2D()(X)\"\n",
    "    X = MaxPooling2D(pool_size=(2, 2))(X)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(2048, activation='relu', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.models.Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape         = reshape[0] + (3, )\n",
    "n_classes           = 12\n",
    "batch_size_train    = 128\n",
    "batch_size_test     = 64\n",
    "epochs              = 60\n",
    "model_cnn           = conv(input_shape = input_shape, classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = compilation.compile(model=model_cnn, Loss=\"cce\", Op='adam', scoring=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backup(epoch):\n",
    "\n",
    "    log_dir = \"./embeding_models/logs\"\n",
    "    callback_tf = tf.keras.callbacks.\\\n",
    "        TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    path_models = \"./embeding_models/model-{epoch:04d}.h5\"\n",
    "    callbacks_models = tf.keras.callbacks.\\\n",
    "        ModelCheckpoint(filepath=path_models, verbose=1)\n",
    "    \n",
    "    path_best_models = f\"./embeding_models/best-{color}-{formats}-model.h5\"\n",
    "    callbacks_best_models = tf.keras.callbacks.\\\n",
    "        ModelCheckpoint(filepath=path_best_models, \n",
    "            monitor=\"val_accuracy\", verbose=1, save_best_only=True)\n",
    "    \n",
    "\n",
    "    earlystopping = tf.keras.callbacks.\\\n",
    "                EarlyStopping(\n",
    "                    monitor='val_accuracy',\n",
    "                    patience=20,\n",
    "                    min_delta=0.01,\n",
    "                    verbose=1,\n",
    "                    restore_best_weights=False\n",
    "                )\n",
    "    \n",
    "    improve_learnin_rate = tf.keras.callbacks. \\\n",
    "        ReduceLROnPlateau(\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    factor=0.1,\n",
    "                    patience=5,\n",
    "                    cooldown=3,\n",
    "                    min_delta=0.001,\n",
    "                    verbose=1\n",
    "                    )\n",
    "    \n",
    "    return callback_tf, callbacks_models, callbacks_best_models, earlystopping, improve_learnin_rate\n",
    "\n",
    "def compile_(\n",
    "        model ,\n",
    "        Loss : str = \"cce\", \n",
    "        Op   : str = \"sgd\", \n",
    "        scoring = ['accuracy']\n",
    "        ):\n",
    "   \n",
    "    model.compile(\n",
    "        loss=tf.losses.CategoricalCrossentropy() if Loss == \"cce\" else tf.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=tf.optimizers.SGD(momentum=0.9) if Op == 'sgd' else tf.optimizers.Adam(),\n",
    "        metrics=scoring\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit_(\n",
    "        model, \n",
    "        X_train : np.ndarray, \n",
    "        X_test  : np.ndarray, \n",
    "        y_train : np.ndarray, \n",
    "        y_test  : np.ndarray, \n",
    "        augment : bool = True, \n",
    "        epochs  : int = 40, \n",
    "        batch_size_train : int = batch_size_train,\n",
    "        batch_size_test_or_val : int = batch_size_test,\n",
    "        subset : str = 'test',\n",
    "        use_callbacks : bool = True,\n",
    "        ):\n",
    "\n",
    "    if use_callbacks:\n",
    "            callback_tf, callbacks_models, callbacks_best_models, earlystopping, improve_learnin_rate = backup(epoch=epochs)\n",
    "        \n",
    "    if augment is True:\n",
    "        datagen_train = data_augmenter_v2()\n",
    "        datagen_test = data_augmenter_v2()\n",
    "        # compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied)\n",
    "        datagen_train.fit(X_train)\n",
    "        datagen_test.fit(X_test)\n",
    "\n",
    "        # fits the model on batches with real-time data augmentation:\n",
    "        if subset == 'validation' : \n",
    "            model.fit(datagen_train.flow(X_train, y_train, batch_size=batch_size_train,\n",
    "                    subset='training'),\n",
    "                    validation_data=datagen_test.flow(X_train, y_train,\n",
    "                    batch_size=batch_size_test_or_val, subset=subset), \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[ \n",
    "                        callback_tf, \n",
    "                        callbacks_models, \n",
    "                        callbacks_best_models,\n",
    "                        earlystopping,\n",
    "                        improve_learnin_rate\n",
    "                        ] if use_callbacks else None\n",
    "                    )\n",
    "\n",
    "        elif subset == 'test':\n",
    "            model.fit(datagen_train.flow(X_train, y_train, batch_size=batch_size_train,\n",
    "                    subset='training'),\n",
    "                    validation_data=datagen_test.flow(X_test, y_test,\n",
    "                    batch_size=batch_size_test_or_val, subset=\"validation\"),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[ \n",
    "                        callback_tf, \n",
    "                        callbacks_models, \n",
    "                        callbacks_best_models,\n",
    "                        earlystopping,\n",
    "                        improve_learnin_rate\n",
    "                        ] if use_callbacks else None\n",
    "                    )\n",
    "        else: print(\"subset should be 'test' ot 'validation'\")\n",
    "    else:\n",
    "        # do not use data augmentation \n",
    "        if subset == 'validation' : \n",
    "            model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_train, y_train),\n",
    "                    verbose=1,\n",
    "                    callbacks=[ \n",
    "                        callback_tf, \n",
    "                        callbacks_models, \n",
    "                        callbacks_best_models,\n",
    "                        earlystopping,\n",
    "                        improve_learnin_rate\n",
    "                        ] if use_callbacks else None\n",
    "                )\n",
    "   \n",
    "        elif subset == 'test':\n",
    "            model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[ \n",
    "                        callback_tf, \n",
    "                        callbacks_models, \n",
    "                        callbacks_best_models,\n",
    "                        earlystopping,\n",
    "                        improve_learnin_rate\n",
    "                        ] if use_callbacks else None\n",
    "                )\n",
    "        else: print(\"subset should be 'test' ot 'validation'\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = fit_(\n",
    "            model       = model_cnn,\n",
    "            X_train     = X_train,\n",
    "            X_test      = X_test,\n",
    "            y_train     = y_train,\n",
    "            y_test      = y_test,\n",
    "            augment     = False,\n",
    "            epochs      = epochs,\n",
    "            batch_size_test_or_val  = batch_size_test,\n",
    "            batch_size_train        = batch_size_train,\n",
    "            use_callbacks           = True,\n",
    "            subset      =\"test\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_cnn.history\n",
    "df = pd.DataFrame(history.history)\n",
    "display(df.head())\n",
    "df.to_csv(f'./DataSet/history_{color}_.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12, 3), sharex=True)\n",
    "df[['loss', 'val_loss']].plot(ax=axes[0], marker='o', title=\"epoch loss for seedling plants\")\n",
    "df[['accuracy', 'val_accuracy']].plot(ax=axes[1], marker='o', title=\"epoch accuracy for seedling plants\")\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].set_xlabel(\"epochs\")\n",
    "\n",
    "axes[0].set_ylabel(\"loss function\")\n",
    "axes[1].set_ylabel(\"accuracy\")\n",
    "axes[1].set_yticks(np.arange(0, 1.1, 0.1).round(1), np.arange(0, 1.1, 0.1).round(1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_model = tf.keras.models.load_model(f\"./embeding_models/best-{color}-{formats}-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = best_cnn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"loss train = {np.round( metrics.history['loss'][0], 4 )}\\nscoring train = {np.round( metrics.history['accuracy'][0], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = best_cnn_model.fit(X_test, y_test)\n",
    "print(f\"loss test = {np.round( metrics.history['loss'][0], 4 )}\\nscoring test = {np.round( metrics.history['accuracy'][0], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_cnn_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_evaluations(y_pred : np.ndarray, y_test : np.ndarray, feature_names : list, average : str=\"micro\", shwo_roc : bool = False ):\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, auc\n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "    y_pred_arg      = np.argmax(y_pred, axis=-1)\n",
    "    y_test_arg      = np.argmax(y_test, axis=-1)\n",
    "    y_scores        = np.max(y_pred, axis=-1, keepdims=False)\n",
    "    fpr             = dict()\n",
    "    tpr             = dict()\n",
    "    roc             = dict()\n",
    "    air_under_curve = dict()\n",
    "    threshold       = dict()\n",
    "\n",
    "    if shwo_roc is True:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        \n",
    "    for i in range(12):\n",
    "        fpr[i], tpr[i], threshold[i]   = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc[i]              = auc(fpr[i], tpr[i])\n",
    "        air_under_curve[i]  = auc(fpr[i], tpr[i])\n",
    "        if shwo_roc is True:\n",
    "            plt.plot(fpr[i], tpr[i], label='%s %d (AUC = %0.2f)' % (feature_names[i], i, air_under_curve[i]))\n",
    "    \n",
    "    if shwo_roc is True:\n",
    "        plt.plot([0, 1], [0, 1], color='k', ls='--')\n",
    "        plt.legend(loc=\"best\", fontsize=\"small\", ncol=2)\n",
    "        plt.xlabel(\"1 - specificity (fpr)\")\n",
    "        plt.ylabel(\"sensitivity (tpr)\")\n",
    "        plt.title(\"Receiver Operating characteristic (ROC) Curves for seedling classification\")\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    #confusution matrix \n",
    "    cm = confusion_matrix(y_true=y_test_arg, y_pred=y_pred_arg)\n",
    "    # classification_repport \n",
    "    cr = classification_report(y_true=y_test_arg, y_pred=y_pred_arg, target_names=feature_names)\n",
    "    # f1_score \n",
    "    fs = f1_score(y_true=y_test_arg, y_pred=y_pred_arg, average=average)\n",
    "    #precision \n",
    "    pr = precision_score(y_true=y_test_arg, y_pred=y_pred_arg, average=average)\n",
    "    # recall\n",
    "    rs = recall_score(y_true=y_test_arg, y_pred=y_pred_arg, average=average)\n",
    "    #\n",
    "    mask = y_test_arg != y_pred_arg \n",
    "\n",
    "    y_test_arg_error = y_test_arg[mask]\n",
    "    y_pred_arg_error = y_pred_arg[mask]\n",
    "\n",
    "    cm_error = confusion_matrix(y_true=y_test_arg_error, y_pred=y_pred_arg_error)\n",
    "\n",
    "    data = {\n",
    "        \"confusion_matrix\" : cm ,\n",
    "        \"classification_report\" : cr,\n",
    "        \"roc\" : [fpr, tpr, threshold],\n",
    "        \"auc\" : air_under_curve,\n",
    "        \"precision\" : pr,\n",
    "        \"recall\" : rs,\n",
    "        \"f1-score\" : fs,\n",
    "        \"mask\" : mask,\n",
    "        \"confusion_matrix_error\" : cm_error,\n",
    "        \"max_scores\" : y_scores\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metric_evaluations(y_pred=y_test_pred, y_test=y_test, feature_names=feature_names, shwo_roc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics['roc']\n",
    "cm, cm_error = metrics['confusion_matrix'], metrics['confusion_matrix_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "sns.heatmap(data=cm, annot=True, cmap=\"plasma\", ax=axes[0], fmt=\"4d\")\n",
    "sns.heatmap(data=cm_error, annot=True, cmap=\"plasma\", ax=axes[1], fmt=\"4d\")\n",
    "for i in range(2):\n",
    "    axes[i].set_xlabel('Predicted Labels')\n",
    "    axes[i].set_ylabel('True Labels')\n",
    "\n",
    "axes[0].set_title(\"Confusion matrix of Prediction : seedling plants\")\n",
    "axes[1].set_title(\"Confusion matrix of Errors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transform(\n",
    "        imgs            : np.ndarray, \n",
    "        dim             : tuple     = (64, 64), \n",
    "        channel         : int       = 1, \n",
    "        radius          : float     = 1, \n",
    "        threshold       : list      = [0, 0.46],\n",
    "        method          : str       = \"numpy\",\n",
    "        img_type        : str       = \"black\",\n",
    "        show_img        : bool      = False,\n",
    "        labels          : list      = []\n",
    "        ):\n",
    "    \n",
    "    from skimage.transform import resize \n",
    "    from skimage.color import rgba2rgb\n",
    "    from modules_python.image_processing.tools import get_mask, change_bg, erorsion_and_dilation\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "    all_imgs = []\n",
    "\n",
    "    f, axes = plt.subplots(1, len(imgs), figsize=(2 * len(imgs), 2))\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        shape = img.shape \n",
    "        if shape[-1] >= 4:\n",
    "            img = rgba2rgb(img)\n",
    "        \n",
    "        img_resize          = resize(img, output_shape=dim)\n",
    "        img_lab             = cv2.cvtColor(img_resize, cv2.COLOR_BGR2LAB)\n",
    "        img_lab[:, :, 0]    = np.clip(img_lab[:, :, 0] / 255.0, 0, 1)\n",
    "        img_lab[:, :, 1]    = np.clip((img_lab[:, :, 1] + 128) / 255.0, 0, 1)\n",
    "        img_lab[:, :, 2]    = np.clip((img_lab[:, :, 2] + 128) / 255.0, 0, 1)\n",
    "        X                   = img_lab.astype(dtype=np.float32).copy() \n",
    "        mask                = get_mask(img=X[..., channel], threshold=threshold, radius=radius, method=method)\n",
    "        mask                = mask * 1.\n",
    "        img_black           = img_resize.astype(dtype=np.float32).copy()\n",
    "        img_black[..., 0]   = img_black[..., 0] * mask * 1.\n",
    "        img_black[..., 1]   = img_black[..., 1] * mask * 1.\n",
    "        img_black[..., 2]   = img_black[..., 2] * mask * 1.\n",
    "        img_white           = img_black.reshape((1, dim[0], dim[1], 3))\n",
    "        img_white           = change_bg(imgs=img_white, lower_color=lower_color, upper_color=upper_color, value=[1, 1, 1])\n",
    "\n",
    "        _ = None \n",
    "\n",
    "        if img_type =='black': _= img_black\n",
    "        if img_type ==\"white\": _= img_white[0]\n",
    "        if img_type == \"mask\": _= mask \n",
    "        if img_type == \"orig\": _= img_resize\n",
    "        if img_type == \"LAB\" : _= img_lab[..., 1]\n",
    "\n",
    "        if show_img is True:\n",
    "            if _ is not None:\n",
    "                axes[i].imshow(_, interpolation=\"nearest\", cmap=\"plasma\")\n",
    "                if labels : axes[i].set_title(label=labels[i])\n",
    "                axes[i].axis('off')\n",
    "            else: pass\n",
    "\n",
    "        _ = _.reshape((dim[0], dim[1], 3 ))\n",
    "\n",
    "        all_imgs.append(_)\n",
    "    plt.show()\n",
    "    \n",
    "    return np.array(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_img_read( urls : str, show_img : str = False, url_labels : list = []):\n",
    "    from PIL import Image\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "    import numpy as np \n",
    "    import time\n",
    "\n",
    "    all_imgs = []\n",
    "\n",
    "    f, axes = plt.subplots(1, len(urls), figsize=(2 * len(urls), 2))\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        image = None\n",
    "        # Replace 'url' with the URL of the image you want to read\n",
    "\n",
    "        try:\n",
    "            start = time.time()\n",
    "            response = requests.get(url)\n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Read the image from the response content\n",
    "                image_data = BytesIO(response.content)\n",
    "                image = Image.open(image_data) #Image.open(image_data)\n",
    "\n",
    "                # You can now work with the 'image' object (e.g., display or process it)\n",
    "                # For example, you can display the image:\n",
    "                image = np.array(image).astype(np.float32) / 255 \n",
    "                if show_img : \n",
    "                    axes[i].imshow(image, interpolation=\"nearest\", cmap=\"plasma\")\n",
    "                    if url_labels: axes[i].set_title(label=url_labels[i])\n",
    "                    axes[i].axis('off')\n",
    "                    \n",
    "                all_imgs.append(image)\n",
    "            else:\n",
    "                print(f\"Failed to retrieve image. Status code: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    end = time.time()\n",
    "    plt.show()\n",
    "    print(f\"response time : {np.round( end-start, 4 )}s\")\n",
    "\n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "\"https://www.nexles.com/articles/wp-content/uploads/2019/07/Sinapis-arvensis-small-plant-1.jpg\",\n",
    "\"https://media.sciencephoto.com/image/c0065348/400wm/C0065348-Cleavers_seedling.jpg\",\n",
    "\"https://www.clemson.edu/cafls/research/weeds/weed-id-bio/broadleaf-weeds-parent/broadleaf-weed-seedlings/chickweed-seedling.jpg\"\n",
    "]\n",
    "url_labels = ['Charlock', \"Cleavers\", 'Common Chickweed']\n",
    "\n",
    "IMG = url_img_read(urls=urls, show_img=True, url_labels=url_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_TRAN = image_transform(imgs=IMG, img_type='black', show_img=True, threshold=[0, 0.46], radius=0.6, dim=reshape[0], labels=url_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = best_cnn_model.predict(IMG_TRAN)\n",
    "y_pred_1_argmax = np.argmax(y_pred_1, axis=-1)\n",
    "pred_dict = {\"Predicted Label\" : [feature_names[i] for i in y_pred_1_argmax], \"True Label\" : url_labels, \"Score\" : list(y_pred_1.max(axis=1)) }\n",
    "pd.DataFrame(pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.applications.mobilenet_v3 \n",
    "process_input = decoder.preprocess_input \n",
    "\n",
    "\n",
    "class Model_Transfer:\n",
    "    def __init__(self) -> None:\n",
    "        self.model = None \n",
    "    def build_model(self, shape : tuple = (128, 128, 3), classes : int  = 12) -> any:\n",
    "        base_model = tf.keras.applications.\\\n",
    "                MobileNetV3Large(input_shape=shape, weights=\"imagenet\", include_top=False) \n",
    "        \n",
    "        inputs = tf.keras.layers.Input(shape=shape)\n",
    "\n",
    "        X = base_model(inputs, trainable=True)\n",
    "        X = process_input(X)\n",
    "        X = tf.keras.layers.BatchNormalization(ax=3)(X)\n",
    "        X = tf.keras.layers.GlobalAveragePooling2D()(X)\n",
    "        X = tf.keras.layers.Dropout(rate=0.8)(X)\n",
    "        X = tf.keras.layers.Dense(units=4096)(X)\n",
    "        X = tf.keras.layers.Dropout(rate=0.5)(X)\n",
    "        X = tf.keras.layers.Dense(units=classes)(X)\n",
    "        X = tf.keras.layers.Activation(activation=\"softmax\")(X)\n",
    "\n",
    "        outputs = X\n",
    "        self.model = tf.keras.models.Model(inputs=inputs, ouputs=outputs)\n",
    "\n",
    "        return self.model \n",
    "    \n",
    "    def compile(self, learning_rate : float = 1e-3, beta_1  :float = 0.9, beta_2 : float = 0.999, loss : str = 'cce') -> None:\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.\\\n",
    "                Adam(learning_rate=learning_rate, beta_1 = beta_1, beta_2=beta_2),\n",
    "            loss=tf.keras.losses.\\\n",
    "                CategoricalCrossentropy(from_logits=True) if loss == \"cce\" else tf.keras.losses.\\\n",
    "                    SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_test, y_test, train_bacth_size : int = 128) -> tuple:\n",
    "        X_train_gen = data_augmenter_v2()\n",
    "        X_test_gen  = data_augmenter_v2()\n",
    "\n",
    "        X_train_gen.fit(X_train, augment=True)\n",
    "        X_test_gen.fit(X_test, augment=True)\n",
    "\n",
    "        self.history = self.model.fit(\n",
    "                        X_train_gen.flow(\n",
    "                            x = X_train, y = y_train, batch_size=train_bacth_size, seed = 3, subset=\"training\"\n",
    "                        ),\n",
    "                        validation_data=X_test_gen.flow(\n",
    "                            x=X_test, y=y_test, batch_size=32, subset='validation', seed=3\n",
    "                        ),\n",
    "                        validation_split = 0.2,\n",
    "                        steps_per_epoch = int(X_train[0] / train_bacth_size),\n",
    "                        verbose = 1,\n",
    "                        callbacks=None\n",
    "                    )\n",
    "        \n",
    "        return self.history, X_train_gen, X_test_gen\n",
    "    \n",
    "    def predict(self,  X_gen, top : int = 2, decoding : bool = False, decode = None):\n",
    "\n",
    "        self.model.trainable = False\n",
    "        y_pred_decode        = None \n",
    "\n",
    "        image_batch, label_batch = next(iter(X_gen))\n",
    "        image_var = tf.Variable(process_input(image_batch))\n",
    "        y_pred = self.model.predict(image_var)\n",
    "\n",
    "        if decoding : y_pred_decode = np.array( decode.decode_predictions(y_pred.numpy(), top=top))\n",
    "\n",
    "        return (y_pred, y_pred_decode, label_batch, self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "\n",
    "pd.plotting.autocorrelation_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components(data, model, images=None, ax=None,\n",
    "                    thumb_frac=0.05, cmap='gray_r', prefit = False):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    if not prefit :\n",
    "        proj = model.fit_transform(data)\n",
    "    else:\n",
    "        proj = data\n",
    "    ax.plot(proj[:, 0], proj[:, 1], '.b')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(data.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # On ne montre pas le points trop proches\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)\n",
    "\n",
    "def plot_reduced_image(image, selector):\n",
    "    mask = selector.get_support()\n",
    "    #toprint = [image[i] if mask[i] == True else 0 for i in range(sum(mask))]\n",
    "    fullimg = np.array([])\n",
    "    cnt = 0\n",
    "    for i in range(62*47):\n",
    "        if mask[i]:\n",
    "            fullimg = np.append(fullimg, image[i-cnt])\n",
    "        else:\n",
    "            fullimg = np.append(fullimg, 0)\n",
    "            cnt += 1\n",
    "    plt.imshow(fullimg.reshape(62,47), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(text, masque, background_color = \"black\"):\n",
    "    # Définir un masque\n",
    "    mask_coloring = np.array(Image.open(str(masque)))\n",
    "    # Définir le calque du nuage des mots\n",
    "    wc = WordCloud(background_color=background_color, max_words=200, \n",
    "                   stopwords=stop_words, mask = mask_coloring, \n",
    "                   max_font_size=50, random_state=42)\n",
    "    # Générer et afficher le nuage de mots\n",
    "    plt.figure(figsize= (20,10))\n",
    "    wc.generate(text)\n",
    "    plt.imshow(wc)\n",
    "    plt.show()\n",
    "\n",
    "plot_word_cloud(text, \"iron.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
